{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_train(subject, list_series):\n",
    "    data = []\n",
    "    for se in list_series:\n",
    "        file_name = 'data/train/subj' + str(subject) + \"_series\" + str(se)\n",
    "        \n",
    "        eeg = pd.read_csv(file_name + '_data.csv')\n",
    "        eeg.drop(\"id\", axis = 1, inplace=True)\n",
    "\n",
    "        evt = pd.read_csv(file_name + '_events.csv')\n",
    "        evt.drop(\"id\", axis = 1, inplace=True)\n",
    "        \n",
    "        data.append( pd.concat( [eeg, evt], axis=1 ) )\n",
    "        \n",
    "    all_data = pd.concat( data, ignore_index = True ).values  \n",
    "    return all_data[:, :-6].astype(float), all_data[:, -6:].astype(bool)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_idx( y, target = None ):\n",
    "    if(target is None) : return target_idx(y, np.zeros(6) )\n",
    "    \n",
    "    assert isinstance(target, (int, list, tuple, np.ndarray ) ), 'wrong type for state'\n",
    "    \n",
    "    if type(target) == int:\n",
    "        return np.argwhere( y[:, target] == 1 )[:,0]\n",
    "    elif isinstance(target, (list, tuple, np.ndarray) ):\n",
    "        return np.argwhere( ( y == np.array( target ) ).all( axis = 1 )  )[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_windows(X, indices, win_size, sampling):\n",
    "    spl_size = sampling*(win_size//sampling)\n",
    "    \n",
    "    X_win = np.zeros( ( len(indices), win_size//sampling,) + X.shape[1:]  )\n",
    "    for i, end in enumerate(indices):\n",
    "        X_win[i] = X[ end - spl_size + 1 : end+1 : sampling]\n",
    "        \n",
    "    return X_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, win_size, sampling, batch_size):\n",
    "    \n",
    "    categs_idx = []\n",
    "    for c in xrange(7):\n",
    "        if c == 6 : c = None\n",
    "        \n",
    "        categ_idx = target_idx(y, c) \n",
    "        #remove indices < winsize\n",
    "        categ_idx = categ_idx[categ_idx >= win_size-1]\n",
    "        \n",
    "        categs_idx.append( categ_idx ) \n",
    "    \n",
    "    #Total batch size\n",
    "    size = sum( batch_size )\n",
    "    \n",
    "    while True:\n",
    "        y_batch = np.zeros( (size,) + y.shape[1:]  )\n",
    "        X_batch = np.zeros( (size, win_size//sampling,) + X.shape[1:]  )\n",
    "        \n",
    "        batch_start = 0\n",
    "        for i, categ_idx in enumerate(categs_idx):\n",
    "            categ_idx_sample = np.random.choice( categ_idx, batch_size[i], replace = False )\n",
    "            y_sample = y[ categ_idx_sample ]\n",
    "            X_sample = get_windows(X, categ_idx_sample, win_size, sampling)\n",
    "\n",
    "            batch_end = batch_start + batch_size[i]\n",
    "            y_batch[batch_start : batch_end] = y_sample\n",
    "            X_batch[batch_start : batch_end] = X_sample\n",
    "            batch_start = batch_end\n",
    "            \n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import AtrousConvolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "# (uncalibrated) 0.87145 !\n",
    "def create_bilayer(shape):\n",
    "    nn = Sequential()\n",
    "\n",
    "    #Dense output\n",
    "    nn.add( Flatten( input_shape=shape ) )\n",
    "    nn.add( Dense(output_dim = 128 ) )\n",
    "    nn.add( Dense(output_dim = 6 ) )\n",
    "    nn.add( Activation('sigmoid') )\n",
    "    \n",
    "    #Compile\n",
    "    nn.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return nn\n",
    "\n",
    "#only one output layer scores (uncalibrated) 0.84894 !\n",
    "def create_dense(shape):\n",
    "    nn = Sequential()\n",
    "\n",
    "    #Dense output\n",
    "    nn.add( Flatten( input_shape=shape ) )\n",
    "    nn.add( Dense(output_dim = 6 ) )\n",
    "    nn.add( Activation('sigmoid') )\n",
    "    \n",
    "    #Compile\n",
    "    nn.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class roc_auc_callback(Callback):\n",
    "    def __init__(self, X_test, y_test):\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={} ):\n",
    "        pred = self.model.predict( self.X_test, batch_size=64 )\n",
    "        logs['val_roc_auc'] = roc_auc_score( self.y_test , pred, average = 'micro' )\n",
    "        print '\\n -', 'val roc auc : ', logs['val_roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_roc_auc', min_delta=0, patience=10, verbose=True, mode='max')\n",
    "\n",
    "def train(subject, w, subsampling, batch_size):\n",
    "    X_train, y_train = load_train(subject, xrange(1,8) )\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    \n",
    "    X_test, y_test = load_train(subject, [8] )\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_test, y_test = batch_generator(X_test, y_test, w, subsampling, batch_size ).next()\n",
    "\n",
    "    model = create_conv( (w//subsampling, 32) )\n",
    "    gen = batch_generator(X_train, y_train, w, subsampling, batch_size )\n",
    "    fit = model.fit_generator(generator = gen, samples_per_epoch = 50*sum(batch_size), nb_epoch = 50,\n",
    "                              validation_data=(X_test, y_test), verbose=True,\n",
    "                              callbacks=[roc_auc_callback(X_test, y_test), early_stopping ] )\n",
    "    \n",
    "    return scaler, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_batch_generator(X, win_size, sampling, batch_size):\n",
    "    start = win_size - 1\n",
    "\n",
    "    while True:\n",
    "        end = min( start+batch_size, len(X) )\n",
    "        X_batch = get_windows(X, range(start, end), win_size, sampling)\n",
    "        start = end\n",
    "        \n",
    "        yield X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_names = ['HandStart', 'FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']\n",
    "\n",
    "def predict(subject, serie, win_size, subsampling, scaler, model):\n",
    "    folder = 'train'\n",
    "    if serie>8 : folder = 'test'\n",
    "    file_name = 'data/'+ folder +'/subj' + str(subject) + \"_series\" + str(serie)  \n",
    "    \n",
    "    eeg = pd.read_csv(file_name + '_data.csv')\n",
    "    ids = eeg.loc[:, 'id']\n",
    "    eeg.drop(\"id\", axis = 1, inplace=True)\n",
    "    \n",
    "    X_test = eeg.values.astype(float)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    pred = np.zeros( (X_test.shape[0], 6) )\n",
    "    \n",
    "    gen = test_batch_generator( X_test, w, subsampling, 64)\n",
    "    pred[win_size-1:] = model.predict_generator( gen, val_samples = X_test.shape[0] - win_size + 1)\n",
    "\n",
    "    result = pd.DataFrame( pred, columns = columns_names )\n",
    "    result.insert(0, 'id', ids)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = 500\n",
    "subsampling = 16\n",
    "\n",
    "batch_size = 20 * np.array( [1, 1, 1, 1, 1, 1, 1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for subject: 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'create_conv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0fe07db1dc7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubject\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'Training for subject:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'scaler'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8a1d2c0cd0b6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(subject, w, subsampling, batch_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_conv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0msubsampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     fit = model.fit_generator(generator = gen, samples_per_epoch = 50*sum(batch_size), nb_epoch = 50,\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'create_conv' is not defined"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for subject in xrange(1,13):\n",
    "    print 'Training for subject:', subject\n",
    "    scaler, model = train(subject, w, subsampling, batch_size)\n",
    "    models.append( {'scaler': scaler, 'model': model} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions( series ):\n",
    "    preds = []\n",
    "    for subject in xrange(1,13):\n",
    "        print 'Predicting for subject:', subject\n",
    "        for serie in series:\n",
    "            print '\\t Predicting for serie:', serie\n",
    "            pred = predict(subject, serie, w, subsampling, models[subject-1]['scaler'], models[subject-1]['model'])\n",
    "            preds.append(pred)\n",
    "    \n",
    "    submission = pd.concat( preds, ignore_index = True )\n",
    "    \n",
    "    str_series = ''\n",
    "    for serie in series: str_series += '_' + str(serie)\n",
    "    submission.to_csv('predictions'+ str_series +'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_predictions([8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_predictions([9, 10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
